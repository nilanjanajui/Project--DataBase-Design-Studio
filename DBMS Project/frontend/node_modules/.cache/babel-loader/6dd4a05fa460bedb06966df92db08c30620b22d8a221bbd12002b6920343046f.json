{"ast":null,"code":"/******************************************************************************\n * Copyright 2024 TypeFox GmbH\n * This program and the accompanying materials are made available under the\n * terms of the MIT License, which is available in the project root.\n ******************************************************************************/\nimport { createToken, createTokenInstance, Lexer } from 'chevrotain';\nimport { DefaultTokenBuilder } from './token-builder.js';\nimport { DEFAULT_TOKENIZE_OPTIONS, DefaultLexer, isTokenTypeArray } from './lexer.js';\nexport const indentationBuilderDefaultOptions = {\n  indentTokenName: 'INDENT',\n  dedentTokenName: 'DEDENT',\n  whitespaceTokenName: 'WS',\n  ignoreIndentationDelimiters: []\n};\nexport var LexingMode;\n(function (LexingMode) {\n  LexingMode[\"REGULAR\"] = \"indentation-sensitive\";\n  LexingMode[\"IGNORE_INDENTATION\"] = \"ignore-indentation\";\n})(LexingMode || (LexingMode = {}));\n/**\n * A token builder that is sensitive to indentation in the input text.\n * It will generate tokens for indentation and dedentation based on the indentation level.\n *\n * The first generic parameter corresponds to the names of terminal tokens,\n * while the second one corresponds to the names of keyword tokens.\n * Both parameters are optional and can be imported from `./generated/ast.js`.\n *\n * Inspired by https://github.com/chevrotain/chevrotain/blob/master/examples/lexer/python_indentation/python_indentation.js\n */\nexport class IndentationAwareTokenBuilder extends DefaultTokenBuilder {\n  constructor(options = indentationBuilderDefaultOptions) {\n    super();\n    /**\n     * The stack stores all the previously matched indentation levels to understand how deeply the next tokens are nested.\n     * The stack is valid for lexing\n     */\n    this.indentationStack = [0];\n    /**\n     * A regular expression to match a series of tabs and/or spaces.\n     * Override this to customize what the indentation is allowed to consist of.\n     */\n    this.whitespaceRegExp = /[ \\t]+/y;\n    this.options = Object.assign(Object.assign({}, indentationBuilderDefaultOptions), options);\n    this.indentTokenType = createToken({\n      name: this.options.indentTokenName,\n      pattern: this.indentMatcher.bind(this),\n      line_breaks: false\n    });\n    this.dedentTokenType = createToken({\n      name: this.options.dedentTokenName,\n      pattern: this.dedentMatcher.bind(this),\n      line_breaks: false\n    });\n  }\n  buildTokens(grammar, options) {\n    const tokenTypes = super.buildTokens(grammar, options);\n    if (!isTokenTypeArray(tokenTypes)) {\n      throw new Error('Invalid tokens built by default builder');\n    }\n    const {\n      indentTokenName,\n      dedentTokenName,\n      whitespaceTokenName,\n      ignoreIndentationDelimiters\n    } = this.options;\n    // Rearrange tokens because whitespace (which is ignored) goes to the beginning by default, consuming indentation as well\n    // Order should be: dedent, indent, spaces\n    let dedent;\n    let indent;\n    let ws;\n    const otherTokens = [];\n    for (const tokenType of tokenTypes) {\n      for (const [begin, end] of ignoreIndentationDelimiters) {\n        if (tokenType.name === begin) {\n          tokenType.PUSH_MODE = LexingMode.IGNORE_INDENTATION;\n        } else if (tokenType.name === end) {\n          tokenType.POP_MODE = true;\n        }\n      }\n      if (tokenType.name === dedentTokenName) {\n        dedent = tokenType;\n      } else if (tokenType.name === indentTokenName) {\n        indent = tokenType;\n      } else if (tokenType.name === whitespaceTokenName) {\n        ws = tokenType;\n      } else {\n        otherTokens.push(tokenType);\n      }\n    }\n    if (!dedent || !indent || !ws) {\n      throw new Error('Some indentation/whitespace tokens not found!');\n    }\n    if (ignoreIndentationDelimiters.length > 0) {\n      const multiModeLexerDef = {\n        modes: {\n          [LexingMode.REGULAR]: [dedent, indent, ...otherTokens, ws],\n          [LexingMode.IGNORE_INDENTATION]: [...otherTokens, ws]\n        },\n        defaultMode: LexingMode.REGULAR\n      };\n      return multiModeLexerDef;\n    } else {\n      return [dedent, indent, ws, ...otherTokens];\n    }\n  }\n  flushLexingReport(text) {\n    const result = super.flushLexingReport(text);\n    return Object.assign(Object.assign({}, result), {\n      remainingDedents: this.flushRemainingDedents(text)\n    });\n  }\n  /**\n   * Helper function to check if the current position is the start of a new line.\n   *\n   * @param text The full input string.\n   * @param offset The current position at which to check\n   * @returns Whether the current position is the start of a new line\n   */\n  isStartOfLine(text, offset) {\n    return offset === 0 || '\\r\\n'.includes(text[offset - 1]);\n  }\n  /**\n   * A helper function used in matching both indents and dedents.\n   *\n   * @param text The full input string.\n   * @param offset The current position at which to attempt a match\n   * @param tokens Previously scanned tokens\n   * @param groups Token Groups\n   * @returns The current and previous indentation levels and the matched whitespace\n   */\n  // eslint-disable-next-line @typescript-eslint/no-unused-vars\n  matchWhitespace(text, offset, tokens, groups) {\n    var _a;\n    this.whitespaceRegExp.lastIndex = offset;\n    const match = this.whitespaceRegExp.exec(text);\n    return {\n      currIndentLevel: (_a = match === null || match === void 0 ? void 0 : match[0].length) !== null && _a !== void 0 ? _a : 0,\n      prevIndentLevel: this.indentationStack.at(-1),\n      match\n    };\n  }\n  /**\n   * Helper function to create an instance of an indentation token.\n   *\n   * @param tokenType Indent or dedent token type\n   * @param text Full input string, used to calculate the line number\n   * @param image The original image of the token (tabs or spaces)\n   * @param offset Current position in the input string\n   * @returns The indentation token instance\n   */\n  createIndentationTokenInstance(tokenType, text, image, offset) {\n    const lineNumber = this.getLineNumber(text, offset);\n    return createTokenInstance(tokenType, image, offset, offset + image.length, lineNumber, lineNumber, 1, image.length);\n  }\n  /**\n   * Helper function to get the line number at a given offset.\n   *\n   * @param text Full input string, used to calculate the line number\n   * @param offset Current position in the input string\n   * @returns The line number at the given offset\n   */\n  getLineNumber(text, offset) {\n    return text.substring(0, offset).split(/\\r\\n|\\r|\\n/).length;\n  }\n  /**\n   * A custom pattern for matching indents\n   *\n   * @param text The full input string.\n   * @param offset The offset at which to attempt a match\n   * @param tokens Previously scanned tokens\n   * @param groups Token Groups\n   */\n  indentMatcher(text, offset, tokens, groups) {\n    if (!this.isStartOfLine(text, offset)) {\n      return null;\n    }\n    const {\n      currIndentLevel,\n      prevIndentLevel,\n      match\n    } = this.matchWhitespace(text, offset, tokens, groups);\n    if (currIndentLevel <= prevIndentLevel) {\n      // shallower indentation (should be matched by dedent)\n      // or same indentation level (should be matched by whitespace and ignored)\n      return null;\n    }\n    this.indentationStack.push(currIndentLevel);\n    return match;\n  }\n  /**\n   * A custom pattern for matching dedents\n   *\n   * @param text The full input string.\n   * @param offset The offset at which to attempt a match\n   * @param tokens Previously scanned tokens\n   * @param groups Token Groups\n   */\n  dedentMatcher(text, offset, tokens, groups) {\n    var _a, _b, _c, _d;\n    if (!this.isStartOfLine(text, offset)) {\n      return null;\n    }\n    const {\n      currIndentLevel,\n      prevIndentLevel,\n      match\n    } = this.matchWhitespace(text, offset, tokens, groups);\n    if (currIndentLevel >= prevIndentLevel) {\n      // bigger indentation (should be matched by indent)\n      // or same indentation level (should be matched by whitespace and ignored)\n      return null;\n    }\n    const matchIndentIndex = this.indentationStack.lastIndexOf(currIndentLevel);\n    // Any dedent must match some previous indentation level.\n    if (matchIndentIndex === -1) {\n      this.diagnostics.push({\n        severity: 'error',\n        message: `Invalid dedent level ${currIndentLevel} at offset: ${offset}. Current indentation stack: ${this.indentationStack}`,\n        offset,\n        length: (_b = (_a = match === null || match === void 0 ? void 0 : match[0]) === null || _a === void 0 ? void 0 : _a.length) !== null && _b !== void 0 ? _b : 0,\n        line: this.getLineNumber(text, offset),\n        column: 1\n      });\n      return null;\n    }\n    const numberOfDedents = this.indentationStack.length - matchIndentIndex - 1;\n    const newlinesBeforeDedent = (_d = (_c = text.substring(0, offset).match(/[\\r\\n]+$/)) === null || _c === void 0 ? void 0 : _c[0].length) !== null && _d !== void 0 ? _d : 1;\n    for (let i = 0; i < numberOfDedents; i++) {\n      const token = this.createIndentationTokenInstance(this.dedentTokenType, text, '',\n      // Dedents are 0-width tokens\n      offset - (newlinesBeforeDedent - 1));\n      tokens.push(token);\n      this.indentationStack.pop();\n    }\n    // Token already added, let the dedentation now be consumed as whitespace (if any) and ignored\n    return null;\n  }\n  buildTerminalToken(terminal) {\n    const tokenType = super.buildTerminalToken(terminal);\n    const {\n      indentTokenName,\n      dedentTokenName,\n      whitespaceTokenName\n    } = this.options;\n    if (tokenType.name === indentTokenName) {\n      return this.indentTokenType;\n    } else if (tokenType.name === dedentTokenName) {\n      return this.dedentTokenType;\n    } else if (tokenType.name === whitespaceTokenName) {\n      return createToken({\n        name: whitespaceTokenName,\n        pattern: this.whitespaceRegExp,\n        group: Lexer.SKIPPED\n      });\n    }\n    return tokenType;\n  }\n  /**\n   * Resets the indentation stack between different runs of the lexer\n   *\n   * @param text Full text that was tokenized\n   * @returns Remaining dedent tokens to match all previous indents at the end of the file\n   */\n  flushRemainingDedents(text) {\n    const remainingDedents = [];\n    while (this.indentationStack.length > 1) {\n      remainingDedents.push(this.createIndentationTokenInstance(this.dedentTokenType, text, '', text.length));\n      this.indentationStack.pop();\n    }\n    this.indentationStack = [0];\n    return remainingDedents;\n  }\n}\n/**\n * A lexer that is aware of indentation in the input text.\n * The only purpose of this lexer is to reset the internal state of the {@link IndentationAwareTokenBuilder}\n * between the tokenization of different text inputs.\n *\n * In your module, you can override the default lexer with this one as such:\n * ```ts\n * parser: {\n *    TokenBuilder: () => new IndentationAwareTokenBuilder(),\n *    Lexer: (services) => new IndentationAwareLexer(services),\n * }\n * ```\n */\nexport class IndentationAwareLexer extends DefaultLexer {\n  constructor(services) {\n    super(services);\n    if (services.parser.TokenBuilder instanceof IndentationAwareTokenBuilder) {\n      this.indentationTokenBuilder = services.parser.TokenBuilder;\n    } else {\n      throw new Error('IndentationAwareLexer requires an accompanying IndentationAwareTokenBuilder');\n    }\n  }\n  tokenize(text, options = DEFAULT_TOKENIZE_OPTIONS) {\n    const result = super.tokenize(text);\n    // consuming all remaining dedents and remove them as they might not be serializable\n    const report = result.report;\n    if ((options === null || options === void 0 ? void 0 : options.mode) === 'full') {\n      // auto-complete document with remaining dedents\n      result.tokens.push(...report.remainingDedents);\n    }\n    report.remainingDedents = [];\n    // remove any \"indent-dedent\" pair with an empty body as these are typically\n    // added by comments or lines with just whitespace but have no real value\n    const {\n      indentTokenType,\n      dedentTokenType\n    } = this.indentationTokenBuilder;\n    // Use tokenTypeIdx for fast comparison\n    const indentTokenIdx = indentTokenType.tokenTypeIdx;\n    const dedentTokenIdx = dedentTokenType.tokenTypeIdx;\n    const cleanTokens = [];\n    const length = result.tokens.length - 1;\n    for (let i = 0; i < length; i++) {\n      const token = result.tokens[i];\n      const nextToken = result.tokens[i + 1];\n      if (token.tokenTypeIdx === indentTokenIdx && nextToken.tokenTypeIdx === dedentTokenIdx) {\n        i++;\n        continue;\n      }\n      cleanTokens.push(token);\n    }\n    // Push last token separately\n    if (length >= 0) {\n      cleanTokens.push(result.tokens[length]);\n    }\n    result.tokens = cleanTokens;\n    return result;\n  }\n}","map":{"version":3,"names":["createToken","createTokenInstance","Lexer","DefaultTokenBuilder","DEFAULT_TOKENIZE_OPTIONS","DefaultLexer","isTokenTypeArray","indentationBuilderDefaultOptions","indentTokenName","dedentTokenName","whitespaceTokenName","ignoreIndentationDelimiters","LexingMode","IndentationAwareTokenBuilder","constructor","options","indentationStack","whitespaceRegExp","Object","assign","indentTokenType","name","pattern","indentMatcher","bind","line_breaks","dedentTokenType","dedentMatcher","buildTokens","grammar","tokenTypes","Error","dedent","indent","ws","otherTokens","tokenType","begin","end","PUSH_MODE","IGNORE_INDENTATION","POP_MODE","push","length","multiModeLexerDef","modes","REGULAR","defaultMode","flushLexingReport","text","result","remainingDedents","flushRemainingDedents","isStartOfLine","offset","includes","matchWhitespace","tokens","groups","lastIndex","match","exec","currIndentLevel","_a","prevIndentLevel","at","createIndentationTokenInstance","image","lineNumber","getLineNumber","substring","split","matchIndentIndex","lastIndexOf","diagnostics","severity","message","_b","line","column","numberOfDedents","newlinesBeforeDedent","_d","_c","i","token","pop","buildTerminalToken","terminal","group","SKIPPED","IndentationAwareLexer","services","parser","TokenBuilder","indentationTokenBuilder","tokenize","report","mode","indentTokenIdx","tokenTypeIdx","dedentTokenIdx","cleanTokens","nextToken"],"sources":["D:\\DBMS\\DBMS Project\\frontend\\node_modules\\langium\\src\\parser\\indentation-aware.ts"],"sourcesContent":["/******************************************************************************\r\n * Copyright 2024 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\nimport type { CustomPatternMatcherFunc, TokenType, IToken, IMultiModeLexerDefinition, TokenVocabulary } from 'chevrotain';\r\nimport type { Grammar, TerminalRule } from '../languages/generated/ast.js';\r\nimport type { LexingReport, TokenBuilderOptions } from './token-builder.js';\r\nimport type { LexerResult, TokenizeOptions } from './lexer.js';\r\nimport type { LangiumCoreServices } from '../services.js';\r\nimport { createToken, createTokenInstance, Lexer } from 'chevrotain';\r\nimport { DefaultTokenBuilder } from './token-builder.js';\r\nimport { DEFAULT_TOKENIZE_OPTIONS, DefaultLexer, isTokenTypeArray } from './lexer.js';\r\n\r\ntype IndentationAwareDelimiter<TokenName extends string> = [begin: TokenName, end: TokenName];\r\n\r\nexport interface IndentationTokenBuilderOptions<TerminalName extends string = string, KeywordName extends string = string> {\r\n    /**\r\n     * The name of the token used to denote indentation in the grammar.\r\n     * A possible definition in the grammar could look like this:\r\n     * ```langium\r\n     * terminal INDENT: ':synthetic-indent:';\r\n     * ```\r\n     *\r\n     * @default 'INDENT'\r\n     */\r\n    indentTokenName: TerminalName;\r\n    /**\r\n     * The name of the token used to denote deindentation in the grammar.\r\n     * A possible definition in the grammar could look like this:\r\n     * ```langium\r\n     * terminal DEDENT: ':synthetic-dedent:';\r\n     * ```\r\n     *\r\n     * @default 'DEDENT'\r\n     */\r\n    dedentTokenName: TerminalName;\r\n    /**\r\n     * The name of the token used to denote whitespace other than indentation and newlines in the grammar.\r\n     * A possible definition in the grammar could look like this:\r\n     * ```langium\r\n     * hidden terminal WS: /[ \\t]+/;\r\n     * ```\r\n     *\r\n     * @default 'WS'\r\n     */\r\n    whitespaceTokenName: TerminalName;\r\n    /**\r\n     * The delimiter tokens inside of which indentation should be ignored and treated as normal whitespace.\r\n     * For example, Python doesn't treat any whitespace between `(` and `)` as significant.\r\n     *\r\n     * Can be either terminal tokens or keyword tokens.\r\n     *\r\n     * @default []\r\n     */\r\n    ignoreIndentationDelimiters: Array<IndentationAwareDelimiter<TerminalName | KeywordName>>\r\n}\r\n\r\nexport const indentationBuilderDefaultOptions: IndentationTokenBuilderOptions = {\r\n    indentTokenName: 'INDENT',\r\n    dedentTokenName: 'DEDENT',\r\n    whitespaceTokenName: 'WS',\r\n    ignoreIndentationDelimiters: [],\r\n};\r\n\r\nexport enum LexingMode {\r\n    REGULAR = 'indentation-sensitive',\r\n    IGNORE_INDENTATION = 'ignore-indentation',\r\n}\r\n\r\nexport interface IndentationLexingReport extends LexingReport {\r\n    /** Dedent tokens that are necessary to close the remaining indents. */\r\n    remainingDedents: IToken[];\r\n}\r\n\r\n/**\r\n * A token builder that is sensitive to indentation in the input text.\r\n * It will generate tokens for indentation and dedentation based on the indentation level.\r\n *\r\n * The first generic parameter corresponds to the names of terminal tokens,\r\n * while the second one corresponds to the names of keyword tokens.\r\n * Both parameters are optional and can be imported from `./generated/ast.js`.\r\n *\r\n * Inspired by https://github.com/chevrotain/chevrotain/blob/master/examples/lexer/python_indentation/python_indentation.js\r\n */\r\nexport class IndentationAwareTokenBuilder<Terminals extends string = string, KeywordName extends string = string> extends DefaultTokenBuilder {\r\n    /**\r\n     * The stack stores all the previously matched indentation levels to understand how deeply the next tokens are nested.\r\n     * The stack is valid for lexing\r\n     */\r\n    protected indentationStack: number[] = [0];\r\n\r\n    readonly options: IndentationTokenBuilderOptions<Terminals, KeywordName>;\r\n\r\n    /**\r\n     * The token type to be used for indentation tokens\r\n     */\r\n    readonly indentTokenType: TokenType;\r\n\r\n    /**\r\n     * The token type to be used for dedentation tokens\r\n     */\r\n    readonly dedentTokenType: TokenType;\r\n\r\n    /**\r\n     * A regular expression to match a series of tabs and/or spaces.\r\n     * Override this to customize what the indentation is allowed to consist of.\r\n     */\r\n    protected whitespaceRegExp = /[ \\t]+/y;\r\n\r\n    constructor(options: Partial<IndentationTokenBuilderOptions<NoInfer<Terminals>, NoInfer<KeywordName>>> = indentationBuilderDefaultOptions as IndentationTokenBuilderOptions<Terminals, KeywordName>) {\r\n        super();\r\n        this.options = {\r\n            ...indentationBuilderDefaultOptions as IndentationTokenBuilderOptions<Terminals, KeywordName>,\r\n            ...options,\r\n        };\r\n\r\n        this.indentTokenType = createToken({\r\n            name: this.options.indentTokenName,\r\n            pattern: this.indentMatcher.bind(this),\r\n            line_breaks: false,\r\n        });\r\n\r\n        this.dedentTokenType = createToken({\r\n            name: this.options.dedentTokenName,\r\n            pattern: this.dedentMatcher.bind(this),\r\n            line_breaks: false,\r\n        });\r\n    }\r\n\r\n    override buildTokens(grammar: Grammar, options?: TokenBuilderOptions | undefined): TokenVocabulary {\r\n        const tokenTypes = super.buildTokens(grammar, options);\r\n        if (!isTokenTypeArray(tokenTypes)) {\r\n            throw new Error('Invalid tokens built by default builder');\r\n        }\r\n\r\n        const { indentTokenName, dedentTokenName, whitespaceTokenName, ignoreIndentationDelimiters } = this.options;\r\n\r\n        // Rearrange tokens because whitespace (which is ignored) goes to the beginning by default, consuming indentation as well\r\n        // Order should be: dedent, indent, spaces\r\n        let dedent: TokenType | undefined;\r\n        let indent: TokenType | undefined;\r\n        let ws: TokenType | undefined;\r\n        const otherTokens: TokenType[] = [];\r\n        for (const tokenType of tokenTypes) {\r\n            for (const [begin, end] of ignoreIndentationDelimiters) {\r\n                if (tokenType.name === begin) {\r\n                    tokenType.PUSH_MODE = LexingMode.IGNORE_INDENTATION;\r\n                } else if (tokenType.name === end) {\r\n                    tokenType.POP_MODE = true;\r\n                }\r\n            }\r\n            if (tokenType.name === dedentTokenName) {\r\n                dedent = tokenType;\r\n            } else if (tokenType.name === indentTokenName) {\r\n                indent = tokenType;\r\n            } else if (tokenType.name === whitespaceTokenName) {\r\n                ws = tokenType;\r\n            } else {\r\n                otherTokens.push(tokenType);\r\n            }\r\n        }\r\n        if (!dedent || !indent || !ws) {\r\n            throw new Error('Some indentation/whitespace tokens not found!');\r\n        }\r\n\r\n        if (ignoreIndentationDelimiters.length > 0) {\r\n            const multiModeLexerDef: IMultiModeLexerDefinition = {\r\n                modes: {\r\n                    [LexingMode.REGULAR]: [dedent, indent, ...otherTokens, ws],\r\n                    [LexingMode.IGNORE_INDENTATION]: [...otherTokens, ws],\r\n                },\r\n                defaultMode: LexingMode.REGULAR,\r\n            };\r\n            return multiModeLexerDef;\r\n        } else {\r\n            return [dedent, indent, ws, ...otherTokens];\r\n        }\r\n    }\r\n\r\n    override flushLexingReport(text: string): IndentationLexingReport {\r\n        const result = super.flushLexingReport(text);\r\n        return {\r\n            ...result,\r\n            remainingDedents: this.flushRemainingDedents(text),\r\n        };\r\n    }\r\n\r\n    /**\r\n     * Helper function to check if the current position is the start of a new line.\r\n     *\r\n     * @param text The full input string.\r\n     * @param offset The current position at which to check\r\n     * @returns Whether the current position is the start of a new line\r\n     */\r\n    protected isStartOfLine(text: string, offset: number): boolean {\r\n        return offset === 0 || '\\r\\n'.includes(text[offset - 1]);\r\n    }\r\n\r\n    /**\r\n     * A helper function used in matching both indents and dedents.\r\n     *\r\n     * @param text The full input string.\r\n     * @param offset The current position at which to attempt a match\r\n     * @param tokens Previously scanned tokens\r\n     * @param groups Token Groups\r\n     * @returns The current and previous indentation levels and the matched whitespace\r\n     */\r\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\r\n    protected matchWhitespace(text: string, offset: number, tokens: IToken[], groups: Record<string, IToken[]>): { currIndentLevel: number, prevIndentLevel: number, match: RegExpExecArray | null } {\r\n        this.whitespaceRegExp.lastIndex = offset;\r\n        const match = this.whitespaceRegExp.exec(text);\r\n        return {\r\n            currIndentLevel: match?.[0].length ?? 0,\r\n            prevIndentLevel: this.indentationStack.at(-1)!,\r\n            match,\r\n        };\r\n    }\r\n\r\n    /**\r\n     * Helper function to create an instance of an indentation token.\r\n     *\r\n     * @param tokenType Indent or dedent token type\r\n     * @param text Full input string, used to calculate the line number\r\n     * @param image The original image of the token (tabs or spaces)\r\n     * @param offset Current position in the input string\r\n     * @returns The indentation token instance\r\n     */\r\n    protected createIndentationTokenInstance(tokenType: TokenType, text: string, image: string, offset: number): IToken {\r\n        const lineNumber = this.getLineNumber(text, offset);\r\n        return createTokenInstance(\r\n            tokenType,\r\n            image,\r\n            offset, offset + image.length,\r\n            lineNumber, lineNumber,\r\n            1, image.length,\r\n        );\r\n    }\r\n\r\n    /**\r\n     * Helper function to get the line number at a given offset.\r\n     *\r\n     * @param text Full input string, used to calculate the line number\r\n     * @param offset Current position in the input string\r\n     * @returns The line number at the given offset\r\n     */\r\n    protected getLineNumber(text: string, offset: number): number {\r\n        return text.substring(0, offset).split(/\\r\\n|\\r|\\n/).length;\r\n    }\r\n\r\n    /**\r\n     * A custom pattern for matching indents\r\n     *\r\n     * @param text The full input string.\r\n     * @param offset The offset at which to attempt a match\r\n     * @param tokens Previously scanned tokens\r\n     * @param groups Token Groups\r\n     */\r\n    protected indentMatcher(text: string, offset: number, tokens: IToken[], groups: Record<string, IToken[]>): ReturnType<CustomPatternMatcherFunc> {\r\n        if (!this.isStartOfLine(text, offset)) {\r\n            return null;\r\n        }\r\n\r\n        const { currIndentLevel, prevIndentLevel, match } = this.matchWhitespace(text, offset, tokens, groups);\r\n\r\n        if (currIndentLevel <= prevIndentLevel) {\r\n            // shallower indentation (should be matched by dedent)\r\n            // or same indentation level (should be matched by whitespace and ignored)\r\n            return null;\r\n        }\r\n\r\n        this.indentationStack.push(currIndentLevel);\r\n\r\n        return match;\r\n    }\r\n\r\n    /**\r\n     * A custom pattern for matching dedents\r\n     *\r\n     * @param text The full input string.\r\n     * @param offset The offset at which to attempt a match\r\n     * @param tokens Previously scanned tokens\r\n     * @param groups Token Groups\r\n     */\r\n    protected dedentMatcher(text: string, offset: number, tokens: IToken[], groups: Record<string, IToken[]>): ReturnType<CustomPatternMatcherFunc> {\r\n        if (!this.isStartOfLine(text, offset)) {\r\n            return null;\r\n        }\r\n\r\n        const { currIndentLevel, prevIndentLevel, match } = this.matchWhitespace(text, offset, tokens, groups);\r\n\r\n        if (currIndentLevel >= prevIndentLevel) {\r\n            // bigger indentation (should be matched by indent)\r\n            // or same indentation level (should be matched by whitespace and ignored)\r\n            return null;\r\n        }\r\n\r\n        const matchIndentIndex = this.indentationStack.lastIndexOf(currIndentLevel);\r\n\r\n        // Any dedent must match some previous indentation level.\r\n        if (matchIndentIndex === -1) {\r\n            this.diagnostics.push({\r\n                severity: 'error',\r\n                message: `Invalid dedent level ${currIndentLevel} at offset: ${offset}. Current indentation stack: ${this.indentationStack}`,\r\n                offset,\r\n                length: match?.[0]?.length ?? 0,\r\n                line: this.getLineNumber(text, offset),\r\n                column: 1\r\n            });\r\n            return null;\r\n        }\r\n\r\n        const numberOfDedents = this.indentationStack.length - matchIndentIndex - 1;\r\n        const newlinesBeforeDedent = text.substring(0, offset).match(/[\\r\\n]+$/)?.[0].length ?? 1;\r\n\r\n        for (let i = 0; i < numberOfDedents; i++) {\r\n            const token = this.createIndentationTokenInstance(\r\n                this.dedentTokenType,\r\n                text,\r\n                '',  // Dedents are 0-width tokens\r\n                offset - (newlinesBeforeDedent - 1), // Place the dedent after the first new line character\r\n            );\r\n            tokens.push(token);\r\n            this.indentationStack.pop();\r\n        }\r\n\r\n        // Token already added, let the dedentation now be consumed as whitespace (if any) and ignored\r\n        return null;\r\n    }\r\n\r\n    protected override buildTerminalToken(terminal: TerminalRule): TokenType {\r\n        const tokenType = super.buildTerminalToken(terminal);\r\n        const { indentTokenName, dedentTokenName, whitespaceTokenName } = this.options;\r\n\r\n        if (tokenType.name === indentTokenName) {\r\n            return this.indentTokenType;\r\n        } else if (tokenType.name === dedentTokenName) {\r\n            return this.dedentTokenType;\r\n        } else if (tokenType.name === whitespaceTokenName) {\r\n            return createToken({\r\n                name: whitespaceTokenName,\r\n                pattern: this.whitespaceRegExp,\r\n                group: Lexer.SKIPPED,\r\n            });\r\n        }\r\n        return tokenType;\r\n    }\r\n\r\n    /**\r\n     * Resets the indentation stack between different runs of the lexer\r\n     *\r\n     * @param text Full text that was tokenized\r\n     * @returns Remaining dedent tokens to match all previous indents at the end of the file\r\n     */\r\n    flushRemainingDedents(text: string): IToken[] {\r\n        const remainingDedents: IToken[] = [];\r\n        while (this.indentationStack.length > 1) {\r\n            remainingDedents.push(\r\n                this.createIndentationTokenInstance(this.dedentTokenType, text, '', text.length)\r\n            );\r\n            this.indentationStack.pop();\r\n        }\r\n\r\n        this.indentationStack = [0];\r\n        return remainingDedents;\r\n    }\r\n}\r\n\r\n/**\r\n * A lexer that is aware of indentation in the input text.\r\n * The only purpose of this lexer is to reset the internal state of the {@link IndentationAwareTokenBuilder}\r\n * between the tokenization of different text inputs.\r\n *\r\n * In your module, you can override the default lexer with this one as such:\r\n * ```ts\r\n * parser: {\r\n *    TokenBuilder: () => new IndentationAwareTokenBuilder(),\r\n *    Lexer: (services) => new IndentationAwareLexer(services),\r\n * }\r\n * ```\r\n */\r\nexport class IndentationAwareLexer extends DefaultLexer {\r\n\r\n    protected readonly indentationTokenBuilder: IndentationAwareTokenBuilder;\r\n\r\n    constructor(services: LangiumCoreServices) {\r\n        super(services);\r\n        if (services.parser.TokenBuilder instanceof IndentationAwareTokenBuilder) {\r\n            this.indentationTokenBuilder = services.parser.TokenBuilder;\r\n        } else {\r\n            throw new Error('IndentationAwareLexer requires an accompanying IndentationAwareTokenBuilder');\r\n        }\r\n    }\r\n\r\n    override tokenize(text: string, options: TokenizeOptions = DEFAULT_TOKENIZE_OPTIONS): LexerResult {\r\n        const result = super.tokenize(text);\r\n\r\n        // consuming all remaining dedents and remove them as they might not be serializable\r\n        const report = result.report as IndentationLexingReport;\r\n        if (options?.mode === 'full') {\r\n            // auto-complete document with remaining dedents\r\n            result.tokens.push(...report.remainingDedents);\r\n        }\r\n        report.remainingDedents = [];\r\n\r\n        // remove any \"indent-dedent\" pair with an empty body as these are typically\r\n        // added by comments or lines with just whitespace but have no real value\r\n        const { indentTokenType, dedentTokenType } = this.indentationTokenBuilder;\r\n        // Use tokenTypeIdx for fast comparison\r\n        const indentTokenIdx = indentTokenType.tokenTypeIdx;\r\n        const dedentTokenIdx = dedentTokenType.tokenTypeIdx;\r\n        const cleanTokens: IToken[] = [];\r\n        const length = result.tokens.length - 1;\r\n        for (let i = 0; i < length; i++) {\r\n            const token = result.tokens[i];\r\n            const nextToken = result.tokens[i + 1];\r\n            if (token.tokenTypeIdx === indentTokenIdx && nextToken.tokenTypeIdx === dedentTokenIdx) {\r\n                i++;\r\n                continue;\r\n            }\r\n\r\n            cleanTokens.push(token);\r\n        }\r\n        // Push last token separately\r\n        if (length >= 0) {\r\n            cleanTokens.push(result.tokens[length]);\r\n        }\r\n        result.tokens = cleanTokens;\r\n\r\n        return result;\r\n    }\r\n}\r\n"],"mappings":"AAAA;;;;;AAWA,SAASA,WAAW,EAAEC,mBAAmB,EAAEC,KAAK,QAAQ,YAAY;AACpE,SAASC,mBAAmB,QAAQ,oBAAoB;AACxD,SAASC,wBAAwB,EAAEC,YAAY,EAAEC,gBAAgB,QAAQ,YAAY;AA8CrF,OAAO,MAAMC,gCAAgC,GAAmC;EAC5EC,eAAe,EAAE,QAAQ;EACzBC,eAAe,EAAE,QAAQ;EACzBC,mBAAmB,EAAE,IAAI;EACzBC,2BAA2B,EAAE;CAChC;AAED,WAAYC,UAGX;AAHD,WAAYA,UAAU;EAClBA,UAAA,qCAAiC;EACjCA,UAAA,6CAAyC;AAC7C,CAAC,EAHWA,UAAU,KAAVA,UAAU;AAUtB;;;;;;;;;;AAUA,OAAM,MAAOC,4BAAqG,SAAQV,mBAAmB;EAyBzIW,YAAYC,OAAA,GAA6FR,gCAA0F;IAC/L,KAAK,EAAE;IAzBX;;;;IAIU,KAAAS,gBAAgB,GAAa,CAAC,CAAC,CAAC;IAc1C;;;;IAIU,KAAAC,gBAAgB,GAAG,SAAS;IAIlC,IAAI,CAACF,OAAO,GAAAG,MAAA,CAAAC,MAAA,CAAAD,MAAA,CAAAC,MAAA,KACLZ,gCAA0F,GAC1FQ,OAAO,CACb;IAED,IAAI,CAACK,eAAe,GAAGpB,WAAW,CAAC;MAC/BqB,IAAI,EAAE,IAAI,CAACN,OAAO,CAACP,eAAe;MAClCc,OAAO,EAAE,IAAI,CAACC,aAAa,CAACC,IAAI,CAAC,IAAI,CAAC;MACtCC,WAAW,EAAE;KAChB,CAAC;IAEF,IAAI,CAACC,eAAe,GAAG1B,WAAW,CAAC;MAC/BqB,IAAI,EAAE,IAAI,CAACN,OAAO,CAACN,eAAe;MAClCa,OAAO,EAAE,IAAI,CAACK,aAAa,CAACH,IAAI,CAAC,IAAI,CAAC;MACtCC,WAAW,EAAE;KAChB,CAAC;EACN;EAESG,WAAWA,CAACC,OAAgB,EAAEd,OAAyC;IAC5E,MAAMe,UAAU,GAAG,KAAK,CAACF,WAAW,CAACC,OAAO,EAAEd,OAAO,CAAC;IACtD,IAAI,CAACT,gBAAgB,CAACwB,UAAU,CAAC,EAAE;MAC/B,MAAM,IAAIC,KAAK,CAAC,yCAAyC,CAAC;IAC9D;IAEA,MAAM;MAAEvB,eAAe;MAAEC,eAAe;MAAEC,mBAAmB;MAAEC;IAA2B,CAAE,GAAG,IAAI,CAACI,OAAO;IAE3G;IACA;IACA,IAAIiB,MAA6B;IACjC,IAAIC,MAA6B;IACjC,IAAIC,EAAyB;IAC7B,MAAMC,WAAW,GAAgB,EAAE;IACnC,KAAK,MAAMC,SAAS,IAAIN,UAAU,EAAE;MAChC,KAAK,MAAM,CAACO,KAAK,EAAEC,GAAG,CAAC,IAAI3B,2BAA2B,EAAE;QACpD,IAAIyB,SAAS,CAACf,IAAI,KAAKgB,KAAK,EAAE;UAC1BD,SAAS,CAACG,SAAS,GAAG3B,UAAU,CAAC4B,kBAAkB;QACvD,CAAC,MAAM,IAAIJ,SAAS,CAACf,IAAI,KAAKiB,GAAG,EAAE;UAC/BF,SAAS,CAACK,QAAQ,GAAG,IAAI;QAC7B;MACJ;MACA,IAAIL,SAAS,CAACf,IAAI,KAAKZ,eAAe,EAAE;QACpCuB,MAAM,GAAGI,SAAS;MACtB,CAAC,MAAM,IAAIA,SAAS,CAACf,IAAI,KAAKb,eAAe,EAAE;QAC3CyB,MAAM,GAAGG,SAAS;MACtB,CAAC,MAAM,IAAIA,SAAS,CAACf,IAAI,KAAKX,mBAAmB,EAAE;QAC/CwB,EAAE,GAAGE,SAAS;MAClB,CAAC,MAAM;QACHD,WAAW,CAACO,IAAI,CAACN,SAAS,CAAC;MAC/B;IACJ;IACA,IAAI,CAACJ,MAAM,IAAI,CAACC,MAAM,IAAI,CAACC,EAAE,EAAE;MAC3B,MAAM,IAAIH,KAAK,CAAC,+CAA+C,CAAC;IACpE;IAEA,IAAIpB,2BAA2B,CAACgC,MAAM,GAAG,CAAC,EAAE;MACxC,MAAMC,iBAAiB,GAA8B;QACjDC,KAAK,EAAE;UACH,CAACjC,UAAU,CAACkC,OAAO,GAAG,CAACd,MAAM,EAAEC,MAAM,EAAE,GAAGE,WAAW,EAAED,EAAE,CAAC;UAC1D,CAACtB,UAAU,CAAC4B,kBAAkB,GAAG,CAAC,GAAGL,WAAW,EAAED,EAAE;SACvD;QACDa,WAAW,EAAEnC,UAAU,CAACkC;OAC3B;MACD,OAAOF,iBAAiB;IAC5B,CAAC,MAAM;MACH,OAAO,CAACZ,MAAM,EAAEC,MAAM,EAAEC,EAAE,EAAE,GAAGC,WAAW,CAAC;IAC/C;EACJ;EAESa,iBAAiBA,CAACC,IAAY;IACnC,MAAMC,MAAM,GAAG,KAAK,CAACF,iBAAiB,CAACC,IAAI,CAAC;IAC5C,OAAA/B,MAAA,CAAAC,MAAA,CAAAD,MAAA,CAAAC,MAAA,KACO+B,MAAM;MACTC,gBAAgB,EAAE,IAAI,CAACC,qBAAqB,CAACH,IAAI;IAAC;EAE1D;EAEA;;;;;;;EAOUI,aAAaA,CAACJ,IAAY,EAAEK,MAAc;IAChD,OAAOA,MAAM,KAAK,CAAC,IAAI,MAAM,CAACC,QAAQ,CAACN,IAAI,CAACK,MAAM,GAAG,CAAC,CAAC,CAAC;EAC5D;EAEA;;;;;;;;;EASA;EACUE,eAAeA,CAACP,IAAY,EAAEK,MAAc,EAAEG,MAAgB,EAAEC,MAAgC;;IACtG,IAAI,CAACzC,gBAAgB,CAAC0C,SAAS,GAAGL,MAAM;IACxC,MAAMM,KAAK,GAAG,IAAI,CAAC3C,gBAAgB,CAAC4C,IAAI,CAACZ,IAAI,CAAC;IAC9C,OAAO;MACHa,eAAe,EAAE,CAAAC,EAAA,GAAAH,KAAK,aAALA,KAAK,uBAALA,KAAK,CAAG,CAAC,EAAEjB,MAAM,cAAAoB,EAAA,cAAAA,EAAA,GAAI,CAAC;MACvCC,eAAe,EAAE,IAAI,CAAChD,gBAAgB,CAACiD,EAAE,CAAC,CAAC,CAAC,CAAE;MAC9CL;KACH;EACL;EAEA;;;;;;;;;EASUM,8BAA8BA,CAAC9B,SAAoB,EAAEa,IAAY,EAAEkB,KAAa,EAAEb,MAAc;IACtG,MAAMc,UAAU,GAAG,IAAI,CAACC,aAAa,CAACpB,IAAI,EAAEK,MAAM,CAAC;IACnD,OAAOrD,mBAAmB,CACtBmC,SAAS,EACT+B,KAAK,EACLb,MAAM,EAAEA,MAAM,GAAGa,KAAK,CAACxB,MAAM,EAC7ByB,UAAU,EAAEA,UAAU,EACtB,CAAC,EAAED,KAAK,CAACxB,MAAM,CAClB;EACL;EAEA;;;;;;;EAOU0B,aAAaA,CAACpB,IAAY,EAAEK,MAAc;IAChD,OAAOL,IAAI,CAACqB,SAAS,CAAC,CAAC,EAAEhB,MAAM,CAAC,CAACiB,KAAK,CAAC,YAAY,CAAC,CAAC5B,MAAM;EAC/D;EAEA;;;;;;;;EAQUpB,aAAaA,CAAC0B,IAAY,EAAEK,MAAc,EAAEG,MAAgB,EAAEC,MAAgC;IACpG,IAAI,CAAC,IAAI,CAACL,aAAa,CAACJ,IAAI,EAAEK,MAAM,CAAC,EAAE;MACnC,OAAO,IAAI;IACf;IAEA,MAAM;MAAEQ,eAAe;MAAEE,eAAe;MAAEJ;IAAK,CAAE,GAAG,IAAI,CAACJ,eAAe,CAACP,IAAI,EAAEK,MAAM,EAAEG,MAAM,EAAEC,MAAM,CAAC;IAEtG,IAAII,eAAe,IAAIE,eAAe,EAAE;MACpC;MACA;MACA,OAAO,IAAI;IACf;IAEA,IAAI,CAAChD,gBAAgB,CAAC0B,IAAI,CAACoB,eAAe,CAAC;IAE3C,OAAOF,KAAK;EAChB;EAEA;;;;;;;;EAQUjC,aAAaA,CAACsB,IAAY,EAAEK,MAAc,EAAEG,MAAgB,EAAEC,MAAgC;;IACpG,IAAI,CAAC,IAAI,CAACL,aAAa,CAACJ,IAAI,EAAEK,MAAM,CAAC,EAAE;MACnC,OAAO,IAAI;IACf;IAEA,MAAM;MAAEQ,eAAe;MAAEE,eAAe;MAAEJ;IAAK,CAAE,GAAG,IAAI,CAACJ,eAAe,CAACP,IAAI,EAAEK,MAAM,EAAEG,MAAM,EAAEC,MAAM,CAAC;IAEtG,IAAII,eAAe,IAAIE,eAAe,EAAE;MACpC;MACA;MACA,OAAO,IAAI;IACf;IAEA,MAAMQ,gBAAgB,GAAG,IAAI,CAACxD,gBAAgB,CAACyD,WAAW,CAACX,eAAe,CAAC;IAE3E;IACA,IAAIU,gBAAgB,KAAK,CAAC,CAAC,EAAE;MACzB,IAAI,CAACE,WAAW,CAAChC,IAAI,CAAC;QAClBiC,QAAQ,EAAE,OAAO;QACjBC,OAAO,EAAE,wBAAwBd,eAAe,eAAeR,MAAM,gCAAgC,IAAI,CAACtC,gBAAgB,EAAE;QAC5HsC,MAAM;QACNX,MAAM,EAAE,CAAAkC,EAAA,IAAAd,EAAA,GAAAH,KAAK,aAALA,KAAK,uBAALA,KAAK,CAAG,CAAC,CAAC,cAAAG,EAAA,uBAAAA,EAAA,CAAEpB,MAAM,cAAAkC,EAAA,cAAAA,EAAA,GAAI,CAAC;QAC/BC,IAAI,EAAE,IAAI,CAACT,aAAa,CAACpB,IAAI,EAAEK,MAAM,CAAC;QACtCyB,MAAM,EAAE;OACX,CAAC;MACF,OAAO,IAAI;IACf;IAEA,MAAMC,eAAe,GAAG,IAAI,CAAChE,gBAAgB,CAAC2B,MAAM,GAAG6B,gBAAgB,GAAG,CAAC;IAC3E,MAAMS,oBAAoB,GAAG,CAAAC,EAAA,IAAAC,EAAA,GAAAlC,IAAI,CAACqB,SAAS,CAAC,CAAC,EAAEhB,MAAM,CAAC,CAACM,KAAK,CAAC,UAAU,CAAC,cAAAuB,EAAA,uBAAAA,EAAA,CAAG,CAAC,EAAExC,MAAM,cAAAuC,EAAA,cAAAA,EAAA,GAAI,CAAC;IAEzF,KAAK,IAAIE,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGJ,eAAe,EAAEI,CAAC,EAAE,EAAE;MACtC,MAAMC,KAAK,GAAG,IAAI,CAACnB,8BAA8B,CAC7C,IAAI,CAACxC,eAAe,EACpBuB,IAAI,EACJ,EAAE;MAAG;MACLK,MAAM,IAAI2B,oBAAoB,GAAG,CAAC,CAAC,CACtC;MACDxB,MAAM,CAACf,IAAI,CAAC2C,KAAK,CAAC;MAClB,IAAI,CAACrE,gBAAgB,CAACsE,GAAG,EAAE;IAC/B;IAEA;IACA,OAAO,IAAI;EACf;EAEmBC,kBAAkBA,CAACC,QAAsB;IACxD,MAAMpD,SAAS,GAAG,KAAK,CAACmD,kBAAkB,CAACC,QAAQ,CAAC;IACpD,MAAM;MAAEhF,eAAe;MAAEC,eAAe;MAAEC;IAAmB,CAAE,GAAG,IAAI,CAACK,OAAO;IAE9E,IAAIqB,SAAS,CAACf,IAAI,KAAKb,eAAe,EAAE;MACpC,OAAO,IAAI,CAACY,eAAe;IAC/B,CAAC,MAAM,IAAIgB,SAAS,CAACf,IAAI,KAAKZ,eAAe,EAAE;MAC3C,OAAO,IAAI,CAACiB,eAAe;IAC/B,CAAC,MAAM,IAAIU,SAAS,CAACf,IAAI,KAAKX,mBAAmB,EAAE;MAC/C,OAAOV,WAAW,CAAC;QACfqB,IAAI,EAAEX,mBAAmB;QACzBY,OAAO,EAAE,IAAI,CAACL,gBAAgB;QAC9BwE,KAAK,EAAEvF,KAAK,CAACwF;OAChB,CAAC;IACN;IACA,OAAOtD,SAAS;EACpB;EAEA;;;;;;EAMAgB,qBAAqBA,CAACH,IAAY;IAC9B,MAAME,gBAAgB,GAAa,EAAE;IACrC,OAAO,IAAI,CAACnC,gBAAgB,CAAC2B,MAAM,GAAG,CAAC,EAAE;MACrCQ,gBAAgB,CAACT,IAAI,CACjB,IAAI,CAACwB,8BAA8B,CAAC,IAAI,CAACxC,eAAe,EAAEuB,IAAI,EAAE,EAAE,EAAEA,IAAI,CAACN,MAAM,CAAC,CACnF;MACD,IAAI,CAAC3B,gBAAgB,CAACsE,GAAG,EAAE;IAC/B;IAEA,IAAI,CAACtE,gBAAgB,GAAG,CAAC,CAAC,CAAC;IAC3B,OAAOmC,gBAAgB;EAC3B;;AAGJ;;;;;;;;;;;;;AAaA,OAAM,MAAOwC,qBAAsB,SAAQtF,YAAY;EAInDS,YAAY8E,QAA6B;IACrC,KAAK,CAACA,QAAQ,CAAC;IACf,IAAIA,QAAQ,CAACC,MAAM,CAACC,YAAY,YAAYjF,4BAA4B,EAAE;MACtE,IAAI,CAACkF,uBAAuB,GAAGH,QAAQ,CAACC,MAAM,CAACC,YAAY;IAC/D,CAAC,MAAM;MACH,MAAM,IAAI/D,KAAK,CAAC,6EAA6E,CAAC;IAClG;EACJ;EAESiE,QAAQA,CAAC/C,IAAY,EAAElC,OAAA,GAA2BX,wBAAwB;IAC/E,MAAM8C,MAAM,GAAG,KAAK,CAAC8C,QAAQ,CAAC/C,IAAI,CAAC;IAEnC;IACA,MAAMgD,MAAM,GAAG/C,MAAM,CAAC+C,MAAiC;IACvD,IAAI,CAAAlF,OAAO,aAAPA,OAAO,uBAAPA,OAAO,CAAEmF,IAAI,MAAK,MAAM,EAAE;MAC1B;MACAhD,MAAM,CAACO,MAAM,CAACf,IAAI,CAAC,GAAGuD,MAAM,CAAC9C,gBAAgB,CAAC;IAClD;IACA8C,MAAM,CAAC9C,gBAAgB,GAAG,EAAE;IAE5B;IACA;IACA,MAAM;MAAE/B,eAAe;MAAEM;IAAe,CAAE,GAAG,IAAI,CAACqE,uBAAuB;IACzE;IACA,MAAMI,cAAc,GAAG/E,eAAe,CAACgF,YAAY;IACnD,MAAMC,cAAc,GAAG3E,eAAe,CAAC0E,YAAY;IACnD,MAAME,WAAW,GAAa,EAAE;IAChC,MAAM3D,MAAM,GAAGO,MAAM,CAACO,MAAM,CAACd,MAAM,GAAG,CAAC;IACvC,KAAK,IAAIyC,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGzC,MAAM,EAAEyC,CAAC,EAAE,EAAE;MAC7B,MAAMC,KAAK,GAAGnC,MAAM,CAACO,MAAM,CAAC2B,CAAC,CAAC;MAC9B,MAAMmB,SAAS,GAAGrD,MAAM,CAACO,MAAM,CAAC2B,CAAC,GAAG,CAAC,CAAC;MACtC,IAAIC,KAAK,CAACe,YAAY,KAAKD,cAAc,IAAII,SAAS,CAACH,YAAY,KAAKC,cAAc,EAAE;QACpFjB,CAAC,EAAE;QACH;MACJ;MAEAkB,WAAW,CAAC5D,IAAI,CAAC2C,KAAK,CAAC;IAC3B;IACA;IACA,IAAI1C,MAAM,IAAI,CAAC,EAAE;MACb2D,WAAW,CAAC5D,IAAI,CAACQ,MAAM,CAACO,MAAM,CAACd,MAAM,CAAC,CAAC;IAC3C;IACAO,MAAM,CAACO,MAAM,GAAG6C,WAAW;IAE3B,OAAOpD,MAAM;EACjB","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}